import asyncio
import logging
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    import fitz  # PyMuPDF
except ImportError:
    logger.warning("PyMuPDF not installed. PDF processing will be limited.")
    fitz = None
import pandas as pd
from dotenv import load_dotenv
import google.generativeai as genai
import time
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI

class CVAgent:
    """
    CV Agent - Ph√¢n t√≠ch CV v√† ·ª©ng vi√™n v·ªõi MCP Server
    """
    
    def __init__(self):
        load_dotenv()
        self.GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
        if not self.GEMINI_API_KEY:
            raise ValueError(" Thi·∫øu GOOGLE_API_KEY trong .env")
        
        # C·∫•u h√¨nh Gemini
        genai.configure(api_key=self.GEMINI_API_KEY)
        
        # LLM cho agent
        self.model_name = "models/gemini-2.5-flash-lite"  # Model ch√≠nh cho CV analysis
        self.llm = ChatGoogleGenerativeAI(
            model="models/gemini-2.5-flash-lite",
            google_api_key=self.GEMINI_API_KEY,
            temperature=0.2,
        )
        
        # Th∆∞ m·ª•c CV m·∫∑c ƒë·ªãnh
        self.cv_folder = Path("cvs")
        self.job_file = Path("job_requirements/job_requirements.xlsx")
        
        # Cache cho quota management
        self._quota_tracker = {"minute": 0, "count": 0}
        self._max_requests_per_minute = 15
    
    def _extract_json_from_text(self, text: str) -> str:
        """Tr√≠ch xu·∫•t JSON object t·ª´ text"""
        try:
            # T√¨m { ƒë·∫ßu ti√™n v√† } cu·ªëi c√πng
            start = text.find('{')
            if start == -1:
                return ""
            
            # ƒê·∫øm braces ƒë·ªÉ t√¨m } cu·ªëi c√πng
            brace_count = 0
            end = start
            for i, char in enumerate(text[start:], start):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        end = i + 1
                        break
            
            return text[start:end]
        except:
            return ""
    
    def _fix_json_quotes(self, text: str) -> str:
        """S·ª≠a quotes trong JSON"""
        try:
            # Thay th·∫ø smart quotes b·∫±ng regular quotes
            text = text.replace('"', '"').replace('"', '"')
            text = text.replace(''', "'").replace(''', "'")
            
            # S·ª≠a unterminated strings
            text = re.sub(r'"[^"]*$', '"', text)  # Th√™m quote cu·ªëi cho string ch∆∞a k·∫øt th√∫c
            text = re.sub(r'"[^"]*"', lambda m: m.group(0) if m.group(0).count('"') % 2 == 0 else m.group(0) + '"', text)
            
            return text
        except:
            return ""
    
    def _extract_clean_json(self, text: str) -> str:
        """Tr√≠ch xu·∫•t JSON s·∫°ch t·ª´ text"""
        try:
            # T√¨m JSON object ho√†n ch·ªânh
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(json_pattern, text, re.DOTALL)
            
            if matches:
                # L·∫•y match d√†i nh·∫•t (c√≥ th·ªÉ l√† JSON ho√†n ch·ªânh nh·∫•t)
                return max(matches, key=len)
            
            return ""
        except:
            return ""
    
    def _check_quota(self) -> Dict[str, Any]:
        """Ki·ªÉm tra quota Gemini"""
        current_minute = int(time.time() / 60)
        
        if self._quota_tracker.get("minute") != current_minute:
            self._quota_tracker = {"minute": current_minute, "count": 0}
        
        if self._quota_tracker["count"] >= self._max_requests_per_minute:
            wait_seconds = 60 - (time.time() % 60)
            return {
                "available": False,
                "wait_seconds": wait_seconds,
                "message": f"Quota exceeded. Wait {wait_seconds:.0f}s"
            }
        
        return {"available": True}
    
    def _increment_quota(self):
        """TƒÉng quota counter"""
        self._quota_tracker["count"] = self._quota_tracker.get("count", 0) + 1
    
    def extract_pdf_with_content(self, pdf_path: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t n·ªôi dung PDF v·ªõi c·∫•u tr√∫c"""
        print(f" CV Agent: Extracting PDF from: {pdf_path}")
        if not os.path.exists(pdf_path):
            print(f" CV Agent: PDF file not found: {pdf_path}")
            raise FileNotFoundError(f"PDF file not found: {pdf_path}")
        
        try:
            doc = fitz.open(pdf_path)
            print(f" CV Agent: PDF opened successfully, {len(doc)} pages")
            pdf_data = {"headings": {}, "all_text": "", "structured_data": {}}
            current_heading = None
        except Exception as e:
            print(f" CV Agent: Error opening PDF: {e}")
            raise
        
        for page_num, page in enumerate(doc, start=1):
            blocks = page.get_text("dict")["blocks"]
            for b in blocks:
                if "lines" not in b:
                    continue
                for line in b["lines"]:
                    line_text = ""
                    max_font = 0
                    bold_count = 0
                    for span in line["spans"]:
                        line_text += span["text"] + " "
                        max_font = max(max_font, span["size"])
                        if span.get("flags", 0) & 2**4:
                            bold_count += 1
                    line_text = line_text.strip()
                    if not line_text:
                        continue
                    pdf_data["all_text"] += line_text + "\n"
                    
                    # Heading detection
                    is_heading = max_font > 12 or bold_count > 0 or line_text.isupper() or line_text.endswith(':')
                    if is_heading:
                        heading_key = f"{line_text} (page {page_num})"
                        pdf_data["headings"][heading_key] = {
                            "font_size": max_font,
                            "bold_count": bold_count,
                            "page": page_num,
                            "text": line_text,
                            "content": ""
                        }
                        current_heading = heading_key
                    else:
                        if current_heading:
                            pdf_data["headings"][current_heading]["content"] += line_text + "\n"
        
        print(f" CV Agent: PDF extraction completed. Text length: {len(pdf_data['all_text'])}")
        print(f" CV Agent: Text preview: {pdf_data['all_text'][:200]}...")
        return pdf_data
    
    def extract_key_info(self, cv_text: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ CV"""
        info = {
            "skills": [],
            "experience_years": "Unknown",
            "education": [],
            "emails": [],
            "phones": []
        }
        
        # Extract emails
        emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', cv_text)
        info["emails"] = emails[:2]
        
        # Extract phones
        phones = re.findall(r'\b(?:\+84|0)\d{9,10}\b', cv_text)
        info["phones"] = phones[:2]
        
        # Look for years of experience
        exp_match = re.search(r'(\d+)\+?\s*(?:years?|nƒÉm|YoE)', cv_text, re.IGNORECASE)
        if exp_match:
            info["experience_years"] = exp_match.group(1) + " years"
        
        # Extract education keywords
        edu_keywords = ['university', 'college', 'bachelor', 'master', 'phd', 'degree', 'ƒë·∫°i h·ªçc', 'cao ƒë·∫≥ng']
        for keyword in edu_keywords:
            if keyword.lower() in cv_text.lower():
                info["education"].append(keyword.capitalize())
        
        # Extract common skills
        skill_keywords = ['python', 'java', 'javascript', 'react', 'sql', 'aws', 'docker', 
                          'machine learning', 'data analysis', 'project management', 'agile',
                          'communication', 'leadership', 'teamwork']
        for skill in skill_keywords:
            if skill.lower() in cv_text.lower():
                info["skills"].append(skill)
        
        return info
    
    def extract_cvs_from_folder(self, folder_path: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t t·∫•t c·∫£ CV PDF t·ª´ th∆∞ m·ª•c"""
        folder_path = Path(folder_path)
        if not folder_path.exists():
            raise FileNotFoundError(f"CV folder not found: {folder_path}")
        
        cv_data = {}
        pdf_files = list(folder_path.glob("*.pdf"))
        if not pdf_files:
            print(f"No CV PDF files found in {folder_path}")
            return {}
        
        print(f"Found {len(pdf_files)} CV PDF files in {folder_path}")
        for pdf_file in pdf_files:
            try:
                print(f"Processing CV: {pdf_file.name}")
                cv_info = self.extract_pdf_with_content(str(pdf_file))
                cv_info["key_info"] = self.extract_key_info(cv_info["all_text"])
                cv_data[pdf_file.name] = cv_info
            except Exception as e:
                cv_data[pdf_file.name] = {"error": str(e)}
        
        return cv_data
    
    def compare_cv_job_with_gemini(self, cv_text: str, job_text: str, cv_key_info: Optional[Dict] = None) -> tuple:
        """So s√°nh CV v·ªõi y√™u c·∫ßu c√¥ng vi·ªác b·∫±ng Gemini AI - ph√¢n t√≠ch chi ti·∫øt t·ª´ng ti√™u ch√≠"""
        
        # Prepare structured prompt
        key_info_str = ""
        if cv_key_info:
            key_info_str = f"""
KEY CANDIDATE INFO:
- Experience: {cv_key_info.get('experience_years', 'Unknown')}
- Skills: {', '.join(cv_key_info.get('skills', [])[:10])}
- Education: {', '.join(cv_key_info.get('education', []))}
- Contact: {', '.join(cv_key_info.get('emails', []))}
"""
        
        prompt = f"""B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng HR. Ph√¢n t√≠ch ·ª©ng vi√™n n√†y so v·ªõi y√™u c·∫ßu c√¥ng vi·ªác.

{key_info_str}

=== N·ªòI DUNG CV ƒê·∫¶Y ƒê·ª¶ ===
{cv_text[:8000]}

=== Y√äU C·∫¶U C√îNG VI·ªÜC ===
{job_text[:2000]}

ƒê√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p (0-100) d·ª±a tr√™n:
1. S·ª± ph√π h·ª£p ch·ª©c danh
2. K·ªπ nƒÉng ph√π h·ª£p  
3. M·ª©c ƒë·ªô kinh nghi·ªám
4. Tr√¨nh ƒë·ªô h·ªçc v·∫•n

QUAN TR·ªåNG: Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá. Gi·ªØ ph√¢n t√≠ch ng·∫Øn g·ªçn (t·ªëi ƒëa 100 k√Ω t·ª± m·ªói ph·∫ßn).

Ch·ªâ tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON n√†y:
{{
    "overall_score": <s·ªë nguy√™n 0-100>,
    "detailed_scores": {{
        "job_title": {{"score": <s·ªë nguy√™n>, "analysis": "<ph√¢n t√≠ch ng·∫Øn>"}},
        "skills": {{"score": <s·ªë nguy√™n>, "analysis": "<ph√¢n t√≠ch ng·∫Øn>"}},
        "experience": {{"score": <s·ªë nguy√™n>, "analysis": "<ph√¢n t√≠ch ng·∫Øn>"}},
        "education": {{"score": <s·ªë nguy√™n>, "analysis": "<ph√¢n t√≠ch ng·∫Øn>"}}
    }},
    "strengths": ["<ƒëi·ªÉm m·∫°nh 1>", "<ƒëi·ªÉm m·∫°nh 2>"],
    "weaknesses": ["<ƒëi·ªÉm y·∫øu 1>", "<ƒëi·ªÉm y·∫øu 2>"],
    "summary": "<t√≥m t·∫Øt ng·∫Øn g·ªçn>"
}}
"""
        
        try:
            print(f" CV Agent: G·ªçi Gemini API cho job...")
            # Check quota
            quota = self._check_quota()
            if not quota["available"]:
                return 0, quota["message"]
            
            self._increment_quota()
            
            # Configure safety settings
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            
            model = genai.GenerativeModel('gemini-2.5-flash-lite')
            response = model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=2000,  # TƒÉng token limit
                    top_p=0.8,
                ),
                safety_settings=safety_settings
            )
            
            # Check if blocked
            if hasattr(response, 'prompt_feedback') and hasattr(response.prompt_feedback, 'block_reason'):
                if response.prompt_feedback.block_reason:
                    return 0, f"Content blocked by safety filter"
            
            result_text = response.text
            print(f" CV Agent: Raw response length: {len(result_text)}")
            print(f" CV Agent: Raw response preview: {result_text[:200]}...")
            
            # Ki·ªÉm tra n·∫øu response b·ªã c·∫Øt
            if not result_text.strip().endswith('}') and '{' in result_text:
                print(f" CV Agent: Response appears to be truncated, attempting to fix...")
                # Th√™m } cu·ªëi n·∫øu thi·∫øu
                if result_text.count('{') > result_text.count('}'):
                    result_text += '}'
            
            # Clean markdown v√† x·ª≠ l√Ω JSON
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()
            
            # X·ª≠ l√Ω JSON v·ªõi error handling t·ªët h∆°n
            try:
                result = json.loads(result_text)
                return result.get("overall_score", 0), result.get("summary", ""), result
            except json.JSONDecodeError as json_err:
                print(f" CV Agent: JSON parsing error: {json_err}")
                print(f" CV Agent: Problematic JSON: {result_text[:500]}...")
                
                # Th·ª≠ nhi·ªÅu c√°ch s·ª≠a JSON
                json_attempts = [
                    # 1. Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
                    re.sub(r'[^\x20-\x7E]', '', result_text.replace('\n', ' ').replace('\r', ' ')),
                    # 2. T√¨m JSON object trong text
                    self._extract_json_from_text(result_text),
                    # 3. S·ª≠a quotes kh√¥ng ƒë√∫ng
                    self._fix_json_quotes(result_text),
                    # 4. Lo·∫°i b·ªè text tr∆∞·ªõc v√† sau JSON
                    self._extract_clean_json(result_text),
                    # 5. S·ª≠a trailing comma
                    self._fix_trailing_comma(result_text)
                ]
                
                for i, cleaned_json in enumerate(json_attempts):
                    if not cleaned_json:
                        continue
                    try:
                        print(f" CV Agent: Trying JSON fix attempt {i+1}")
                        result = json.loads(cleaned_json)
                        print(f" CV Agent: JSON parsing successful with attempt {i+1}")
                        return result.get("overall_score", 0), result.get("summary", ""), result
                    except Exception as e:
                        print(f" CV Agent: Attempt {i+1} failed: {str(e)[:50]}")
                        continue
                
                # Fallback: t·∫°o k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh
                print(f" CV Agent: All JSON parsing attempts failed, using fallback")
                return 0, f"JSON parsing error: {str(json_err)[:100]}", {}
            
        except Exception as e:
            print(f" CV Agent: L·ªói trong compare_cv_job_with_gemini: {e}")
            error_msg = str(e)
            
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                print(f"\nüö®üö®üö® RATE LIMIT ERROR 429 üö®üö®üö®")
                print(f"üì± Model ƒëang s·ª≠ d·ª•ng: {self.model_name}")
                print(f"‚ùå L·ªói: {error_msg}")
                print(f"‚è∞ Th·ªùi gian: {datetime.now().strftime('%H:%M:%S')}")
                print(f"üõë H·ªá th·ªëng ƒë√£ d·ª´ng ph√¢n t√≠ch ƒë·ªÉ tr√°nh l·ªói API")
                print(f"üí° Gi·∫£i ph√°p: Vui l√≤ng th·ª≠ l·∫°i sau 1-2 ph√∫t")
                print(f"üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®üö®")
                return 0, f"üö® RATE LIMIT ERROR 429: {error_msg[:200]}", {}
            else:
                print(f" Gemini error: {error_msg[:100]}")
                return 0, f"API Error: {error_msg[:100]}", {}
    
    async def process(self, user_input: str, uploaded_files: List[str] = None) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω y√™u c·∫ßu ph√¢n t√≠ch CV
        """
        try:
            logger.info(f"X·ª≠ l√Ω y√™u c·∫ßu: {user_input}")
            logger.info(f"Uploaded files: {uploaded_files}")
            logger.info(f"Model ƒëang s·ª≠ d·ª•ng: {self.model_name}")
            
            # N·∫øu c√≥ file ƒë∆∞·ª£c upload, so s√°nh v·ªõi job requirements
            if uploaded_files and len(uploaded_files) > 0:
                print(" CV Agent: C√≥ file ƒë∆∞·ª£c upload, so s√°nh v·ªõi job requirements")
                return await self._compare_uploaded_cv_with_jobs(uploaded_files[0])
            else:
                # N·∫øu kh√¥ng c√≥ file, qu√©t t·∫•t c·∫£ CV trong th∆∞ m·ª•c cvs/
                print(" CV Agent: Kh√¥ng c√≥ file upload, qu√©t t·∫•t c·∫£ CV trong th∆∞ m·ª•c")
                return await self._analyze_all_cvs()
                
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    async def _analyze_all_cvs(self) -> Dict[str, Any]:
        """Ph√¢n t√≠ch t·∫•t c·∫£ CV trong th∆∞ m·ª•c cvs/"""
        try:
            print("üîÑ CV Agent: ƒêang qu√©t t·∫•t c·∫£ CV trong th∆∞ m·ª•c cvs/...")
            
            # L·∫•y danh s√°ch t·∫•t c·∫£ file PDF trong th∆∞ m·ª•c cvs/
            cv_files = list(self.cv_folder.glob("*.pdf"))
            
            if not cv_files:
                return {
                    "agent": "cv_agent",
                    "status": "success",
                    "result": {
                        "message": "Kh√¥ng t√¨m th·∫•y CV n√†o trong th∆∞ m·ª•c cvs/",
                        "cv_count": 0,
                        "cv_evaluations": []
                    }
                }
            
            print(f" CV Agent: T√¨m th·∫•y {len(cv_files)} CV files")
            
            # ƒê·ªçc job requirements
            job_requirements = self._load_job_requirements()
            
            # Ph√¢n t√≠ch t·ª´ng CV
            cv_evaluations = []
            for cv_file in cv_files:
                print(f" CV Agent: ƒêang ph√¢n t√≠ch {cv_file.name}")
                evaluation = await self._evaluate_single_cv(str(cv_file), job_requirements)
                cv_evaluations.append(evaluation)
            
            return {
                "agent": "cv_agent",
                "status": "success",
                "result": {
                    "message": f"ƒê√£ ph√¢n t√≠ch {len(cv_files)} CV",
                    "cv_count": len(cv_files),
                    "cv_evaluations": cv_evaluations
                }
            }
            
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__
            }

    async def _compare_uploaded_cv_with_jobs(self, uploaded_file: str) -> Dict[str, Any]:
        """So s√°nh CV ƒë∆∞·ª£c upload v·ªõi job requirements"""
        try:
            print(f" CV Agent: So s√°nh CV {uploaded_file} v·ªõi job requirements")
            
            # ƒê·ªçc job requirements
            job_requirements = self._load_job_requirements()
            
            # T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß cho file upload
            if not uploaded_file.startswith('/') and not uploaded_file.startswith('uploads/'):
                cv_path = f"uploads/{uploaded_file}"
            else:
                cv_path = uploaded_file
            
            print(f" CV Agent: ƒê∆∞·ªùng d·∫´n CV: {cv_path}")
            
            # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
            if not Path(cv_path).exists():
                return {
                    "agent": "cv_agent",
                    "status": "error",
                    "error": f"File kh√¥ng t·ªìn t·∫°i: {cv_path}",
                    "error_type": "FileNotFoundError"
                }
            
            # Ph√¢n t√≠ch CV ƒë∆∞·ª£c upload
            print(f" CV Agent: B·∫Øt ƒë·∫ßu ƒë√°nh gi√° CV...")
            evaluation = await self._evaluate_single_cv(cv_path, job_requirements)
            print(f" CV Agent: Ho√†n th√†nh ƒë√°nh gi√° CV")
            print(f" CV Agent: Evaluation status: {evaluation.get('status')}")
            
            return {
                "agent": "cv_agent",
                "status": "success",
                "result": {
                    "message": f"ƒê√£ ph√¢n t√≠ch CV {uploaded_file}",
                    "cv_count": 1,
                    "cv_evaluations": [evaluation]
                }
            }
            
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__
            }

    def _load_job_requirements(self) -> Dict[str, Any]:
        """ƒê·ªçc job requirements t·ª´ Excel file"""
        try:
            if not self.job_file.exists():
                print(f" CV Agent: Kh√¥ng t√¨m th·∫•y file {self.job_file}")
                return {}
            
            # ƒê·ªçc Excel file
            df = pd.read_excel(self.job_file)
            print(f" CV Agent: ƒê√£ ƒë·ªçc {len(df)} job requirements")
            
            # Convert to dict format
            job_requirements = {}
            for _, row in df.iterrows():
                job_title = row.get('Job Title', '')
                if job_title:
                    job_requirements[job_title] = {
                        'skills_required': row.get('Skills Required', ''),
                        'experience_required': row.get('Experience Required', ''),
                        'education_required': row.get('Education Required', ''),
                        'responsibilities': row.get('Responsibilities', ''),
                        'preferred_keywords': row.get('Preferred Keywords', '')
                    }
            
            return job_requirements
            
        except Exception as e:
            print(f" CV Agent: L·ªói ƒë·ªçc job requirements: {e}")
            return {}

    async def _evaluate_single_cv(self, cv_path: str, job_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """ƒê√°nh gi√° m·ªôt CV c·ª• th·ªÉ"""
        try:
            print(f" CV Agent: ƒêang ƒë√°nh gi√° CV: {cv_path}")
            print(f" CV Agent: Job requirements c√≥ {len(job_requirements)} jobs")
            
            # Extract CV content
            cv_data = self.extract_pdf_with_content(cv_path)
            print(f" CV Agent: CV data extracted: {bool(cv_data)}")
            print(f" CV Agent: CV data keys: {list(cv_data.keys()) if cv_data else 'None'}")
            print(f" CV Agent: All text length: {len(cv_data.get('all_text', '')) if cv_data else 0}")
            
            if not cv_data or not cv_data.get('all_text'):
                print(f" CV Agent: Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung CV t·ª´ {cv_path}")
                print(f" CV Agent: CV data: {cv_data}")
                return {
                    "cv_name": Path(cv_path).name,
                    "status": "error",
                    "error": "Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung CV"
                }
            
            cv_text = cv_data['all_text']
            cv_key_info = self.extract_key_info(cv_text)
            
            # So s√°nh v·ªõi t·ª´ng job requirement
            evaluations = []
            for job_title, job_req in job_requirements.items():
                print(f" CV Agent: ƒêang so s√°nh v·ªõi job: {job_title}")
                job_text = f"""
                Job Title: {job_title}
                Skills Required: {job_req.get('skills_required', '')}
                Experience Required: {job_req.get('experience_required', '')}
                Education Required: {job_req.get('education_required', '')}
                Responsibilities: {job_req.get('responsibilities', '')}
                Preferred Keywords: {job_req.get('preferred_keywords', '')}
                """
                
                try:
                    print(f" CV Agent: B·∫Øt ƒë·∫ßu ƒë√°nh gi√° {job_title}...")
                    # S·ª≠ d·ª•ng Gemini ƒë·ªÉ ƒë√°nh gi√° v·ªõi ph√¢n t√≠ch chi ti·∫øt
                    score, analysis, detailed_result = self.compare_cv_job_with_gemini(cv_text, job_text, cv_key_info)
                    print(f" CV Agent: K·∫øt qu·∫£ ƒë√°nh gi√° {job_title}: {score}%")
                    
                    # Ki·ªÉm tra rate limit
                    if "Rate limit exceeded" in analysis or "429" in analysis:
                        print(f" CV Agent: Rate limit hit! D·ª´ng ph√¢n t√≠ch...")
                        return {
                            "cv_name": Path(cv_path).name,
                            "status": "error",
                            "error": f"üö® RATE LIMIT ERROR 429: {analysis}",
                            "cv_key_info": cv_key_info
                        }
                    
                    # T·∫°o k·∫øt qu·∫£ ƒë√°nh gi√°
                    evaluation_result = {
                        "job_title": job_title,
                        "score": score,
                        "analysis": analysis,
                        "detailed_scores": detailed_result.get("detailed_scores", {}),
                        "strengths": detailed_result.get("strengths", []),
                        "weaknesses": detailed_result.get("weaknesses", []),
                        "cv_key_info": cv_key_info
                    }
                    
                    evaluations.append(evaluation_result)
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ realtime
                    print(f"\n{'='*60}")
                    print(f"üìä K·∫æT QU·∫¢ PH√ÇN T√çCH REALTIME")
                    print(f"{'='*60}")
                    print(f"üë§ CV: {Path(cv_path).name}")
                    print(f"üíº Job: {job_title}")
                    print(f"‚≠ê ƒêi·ªÉm s·ªë: {score}%")
                    print(f"üìù Ph√¢n t√≠ch: {analysis}")
                    
                    # Hi·ªÉn th·ªã ƒëi·ªÉm chi ti·∫øt
                    if detailed_result.get("detailed_scores"):
                        print(f"\nüìä Ph√¢n t√≠ch chi ti·∫øt:")
                        for criteria, data in detailed_result["detailed_scores"].items():
                            criteria_name = {
                                "job_title": "Ch·ª©c danh",
                                "skills": "K·ªπ nƒÉng", 
                                "experience": "Kinh nghi·ªám",
                                "education": "H·ªçc v·∫•n"
                            }.get(criteria, criteria)
                            print(f"  - {criteria_name}: {data.get('score', 0)}%")
                    
                    # Hi·ªÉn th·ªã ƒëi·ªÉm m·∫°nh/y·∫øu
                    if detailed_result.get("strengths"):
                        print(f"\n‚úÖ ƒêi·ªÉm m·∫°nh:")
                        for strength in detailed_result["strengths"][:3]:  # Ch·ªâ hi·ªÉn th·ªã 3 ƒëi·ªÉm m·∫°nh ƒë·∫ßu
                            print(f"  + {strength}")
                    
                    if detailed_result.get("weaknesses"):
                        print(f"\n‚ùå ƒêi·ªÉm c·∫ßn c·∫£i thi·ªán:")
                        for weakness in detailed_result["weaknesses"][:3]:  # Ch·ªâ hi·ªÉn th·ªã 3 ƒëi·ªÉm y·∫øu ƒë·∫ßu
                            print(f"  - {weakness}")
                    
                    print(f"{'='*60}\n")
                except Exception as e:
                    print(f" CV Agent: L·ªói ƒë√°nh gi√° {job_title}: {e}")
                    print(f" CV Agent: Ti·∫øp t·ª•c v·ªõi job ti·∫øp theo...")
                    evaluations.append({
                        "job_title": job_title,
                        "score": 0,
                        "analysis": f"L·ªói ƒë√°nh gi√°: {str(e)}",
                        "detailed_scores": {},
                        "strengths": [],
                        "weaknesses": [],
                        "cv_key_info": cv_key_info
                    })
            
            # T√¨m job ph√π h·ª£p nh·∫•t
            best_match = max(evaluations, key=lambda x: x['score'])
            
            # T√≠nh ƒëi·ªÉm trung b√¨nh
            valid_scores = [e['score'] for e in evaluations if isinstance(e['score'], (int, float))]
            average_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0
            
            print(f" CV Agent: Ho√†n th√†nh ƒë√°nh gi√° {len(evaluations)} jobs")
            print(f" CV Agent: Best match: {best_match['job_title']} ({best_match['score']}%)")
            print(f" CV Agent: Average score: {average_score:.1f}%")
            
            return {
                "cv_name": Path(cv_path).name,
                "cv_key_info": cv_key_info,
                "best_match": best_match,
                "all_evaluations": evaluations,
                "average_score": round(average_score, 2),
                "status": "success"
            }
            
        except Exception as e:
            return {
                "cv_name": Path(cv_path).name,
                "status": "error",
                "error": str(e)
            }

    async def _analyze_cvs(self) -> Dict[str, Any]:
        """Ph√¢n t√≠ch t·∫•t c·∫£ CV trong th∆∞ m·ª•c"""
        try:
            print("üîÑ CV Agent: ƒêang t·∫£i d·ªØ li·ªáu CV...")
            cv_data = self.extract_cvs_from_folder(str(self.cv_folder))
            
            if not cv_data:
                return {
                    "agent": "cv_agent",
                    "status": "success",
                    "result": {
                        "message": "Kh√¥ng t√¨m th·∫•y CV n√†o trong th∆∞ m·ª•c",
                        "cv_count": 0
                    }
                }
            
            # T·∫°o b√°o c√°o ph√¢n t√≠ch
            analysis_result = {
                "total_cvs": len(cv_data),
                "cv_summaries": [],
                "skills_analysis": {},
                "experience_analysis": {}
            }
            
            all_skills = []
            all_experience = []
            
            for cv_name, cv_info in cv_data.items():
                if "error" in cv_info:
                    continue
                
                key_info = cv_info.get("key_info", {})
                skills = key_info.get("skills", [])
                experience = key_info.get("experience_years", "Unknown")
                
                all_skills.extend(skills)
                if experience != "Unknown":
                    all_experience.append(experience)
                
                analysis_result["cv_summaries"].append({
                    "cv_name": cv_name,
                    "skills": skills,
                    "experience": experience,
                    "education": key_info.get("education", []),
                    "contact": {
                        "emails": key_info.get("emails", []),
                        "phones": key_info.get("phones", [])
                    }
                })
            
            # Ph√¢n t√≠ch k·ªπ nƒÉng
            from collections import Counter
            skills_counter = Counter(all_skills)
            analysis_result["skills_analysis"] = dict(skills_counter.most_common(10))
            
            # Ph√¢n t√≠ch kinh nghi·ªám
            analysis_result["experience_analysis"] = {
                "total_with_experience": len(all_experience),
                "experience_distribution": dict(Counter(all_experience))
            }
            
            return {
                "agent": "cv_agent",
                "status": "success",
                "result": analysis_result
            }
            
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e)
            }
    
    async def _compare_cvs_with_jobs(self) -> Dict[str, Any]:
        """So s√°nh CV v·ªõi y√™u c·∫ßu c√¥ng vi·ªác"""
        try:
            print("üîÑ CV Agent: ƒêang t·∫£i d·ªØ li·ªáu CV v√† Job requirements...")
            
            # Load CV data
            cv_data = self.extract_cvs_from_folder(str(self.cv_folder))
            
            # Load job requirements
            job_data = {}
            if self.job_file.exists():
                df = pd.read_excel(self.job_file)
                for idx, row in df.iterrows():
                    job_name = row.get('Job Title', f'Job_{idx}')
                    job_data[job_name] = row.to_dict()
            
            if not job_data:
                return {
                    "agent": "cv_agent",
                    "status": "success",
                    "result": {
                        "message": "Kh√¥ng t√¨m th·∫•y job requirements",
                        "cv_count": len(cv_data)
                    }
                }
            
            # So s√°nh t·ª´ng CV v·ªõi t·ª´ng job
            match_results = {}
            total_pairs = len(job_data) * len(cv_data)
            current = 0
            
            for job_name, job_info in job_data.items():
                job_text = " ".join(str(v) for k, v in job_info.items())
                for cv_name, cv_info in cv_data.items():
                    current += 1
                    print(f"  [{current}/{total_pairs}] {job_name[:25]}... ‚Üî {cv_name[:25]}...")
                    
                    if "error" in cv_info:
                        score, summary = 0, "CV extraction error"
                    else:
                        cv_text = cv_info.get("all_text", "")
                        key_info = cv_info.get("key_info", {})
                        
                        if not cv_text:
                            score, summary = 0, "Empty CV"
                        else:
                            score, summary = self.compare_cv_job_with_gemini(cv_text, job_text, key_info)
                            time.sleep(2)  # Delay ƒë·ªÉ tr√°nh rate limit
                    
                    key = f"{job_name} -> {cv_name}"
                    match_results[key] = {
                        "match_percentage": score,
                        "summary": summary
                    }
                    print(f"    ‚úì Score: {score}/100")
            
            return {
                "agent": "cv_agent",
                "status": "success",
                "result": {
                    "total_cvs": len(cv_data),
                    "total_jobs": len(job_data),
                    "match_results": match_results
                }
            }
            
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e)
            }
    
    def _fix_trailing_comma(self, text: str) -> str:
        """S·ª≠a trailing comma trong JSON"""
        try:
            # T√¨m JSON object trong text
            if "```json" in text:
                json_text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                json_text = text.split("```")[1].split("```")[0].strip()
            else:
                json_text = text.strip()
            
            # S·ª≠a trailing comma
            # Lo·∫°i b·ªè trailing comma tr∆∞·ªõc }
            json_text = re.sub(r',\s*}', '}', json_text)
            # Lo·∫°i b·ªè trailing comma tr∆∞·ªõc ]
            json_text = re.sub(r',\s*]', ']', json_text)
            
            return json_text
        except Exception:
            return ""
    
    async def _find_candidates(self, user_input: str) -> Dict[str, Any]:
        """T√¨m ·ª©ng vi√™n ph√π h·ª£p d·ª±a tr√™n y√™u c·∫ßu"""
        try:
            print(" CV Agent: T√¨m ki·∫øm ·ª©ng vi√™n ph√π h·ª£p...")
            
            # Load CV data
            cv_data = self.extract_cvs_from_folder(str(self.cv_folder))
            
            if not cv_data:
                return {
                    "agent": "cv_agent",
                    "status": "success",
                    "result": {
                        "message": "Kh√¥ng t√¨m th·∫•y CV n√†o",
                        "candidates": []
                    }
                }
            
            # T√¨m ki·∫øm d·ª±a tr√™n t·ª´ kh√≥a trong user_input
            search_keywords = user_input.lower().split()
            candidates = []
            
            for cv_name, cv_info in cv_data.items():
                if "error" in cv_info:
                    continue
                
                cv_text = cv_info.get("all_text", "").lower()
                key_info = cv_info.get("key_info", {})
                skills = key_info.get("skills", [])
                
                # T√≠nh ƒëi·ªÉm ph√π h·ª£p
                match_score = 0
                matched_keywords = []
                
                for keyword in search_keywords:
                    if keyword in cv_text:
                        match_score += 1
                        matched_keywords.append(keyword)
                    elif any(keyword in skill.lower() for skill in skills):
                        match_score += 2  # Skills match c√≥ tr·ªçng s·ªë cao h∆°n
                        matched_keywords.append(f"skill:{keyword}")
                
                if match_score > 0:
                    candidates.append({
                        "cv_name": cv_name,
                        "match_score": match_score,
                        "matched_keywords": matched_keywords,
                        "skills": skills,
                        "experience": key_info.get("experience_years", "Unknown"),
                        "summary": f"Ph√π h·ª£p v·ªõi {len(matched_keywords)} ti√™u ch√≠"
                    })
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm ph√π h·ª£p
            candidates.sort(key=lambda x: x["match_score"], reverse=True)
            
            return {
                "agent": "cv_agent",
                "status": "success",
                "result": {
                    "search_query": user_input,
                    "total_candidates": len(candidates),
                    "top_candidates": candidates[:5]  # Top 5 ·ª©ng vi√™n
                }
            }
            
        except Exception as e:
            return {
                "agent": "cv_agent",
                "status": "error",
                "error": str(e)
            }

# Test function
async def test_cv_agent():
    agent = CVAgent()
    
    test_cases = [
        "Ph√¢n t√≠ch t·∫•t c·∫£ CV",
        "So s√°nh CV v·ªõi y√™u c·∫ßu c√¥ng vi·ªác",
        "T√¨m ·ª©ng vi√™n c√≥ kinh nghi·ªám Python",
        "T√¨m ·ª©ng vi√™n c√≥ b·∫±ng ƒë·∫°i h·ªçc"
    ]
    
    for test_input in test_cases:
        print(f"\n{'='*50}")
        print(f"Test: {test_input}")
        result = await agent.process(test_input)
        print(f"Result: {json.dumps(result, ensure_ascii=False, indent=2)}")

if __name__ == "__main__":
    asyncio.run(test_cv_agent())
